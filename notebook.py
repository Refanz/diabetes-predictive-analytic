# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Refanz/diabetes-predictive-analytic/blob/master/notebook.ipynb

# **Proyek Prediksi Analitik: [Diabetes]**

## **Import Library**

- Pandas: untuk manipulasi dan analisis data
- Numpy: untuk komputasi numerik
- Seaborn: untuk visualisasi data statistik
- Matplotlib: untuk visualisasi data
- Scikit-learn (sklearn): untuk machine learning
"""

# Melakukan import library
from collections import Counter

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler

"""## **Loading Data**

Melakukan load dataset dari lokal menggunakan fungsi read_csv dari library pandas
"""

# Membaca berkas CSV
diabetes_df = pd.read_csv("data/diabetes-dataset.csv")
diabetes_df.head()

"""## **Exploratory Data Analysis (EDA)**

**Mendapatkan informasi dari dataset dengan fungsi info()**
"""

# Mendapatkan informasi dari dataset
diabetes_df.info()

"""**Melihat deskripsi statistik dari dataset menggunakan fungsi describe()**"""

diabetes_df.describe()

"""**Mengecek apakah ada nilai kosong dengan fungsi isna()**"""

# Mengecek apakah ada data yang kosong
diabetes_df.isna().sum()

"""**Mengecek apakah ada data yang duplikat pada dataset dengan fungsi duplicated()**"""

# Menghitung jumlah duplikasi data
print("Jumlah duplikasi:", diabetes_df.duplicated().sum())

"""**Mendapatkan kolom yang memiliki nilai 0**"""

# Mengambil kolom selain target
df_columns = diabetes_df.drop(columns=['Outcome', 'Pregnancies']).columns

# Membuat list untuk menampung kolom yang memiliki nilai 0
zero_columns = []

# Menghitung jumlah missing value
for col in df_columns:
    miss_val_count = (diabetes_df[col] == 0).sum()

    if miss_val_count != 0:
        zero_columns.append(col)
        print(f"{col}: {miss_val_count}")

"""**Mengubah nilai 0 menjadi Nan agar mempermudah proses imputasi**"""

# Membuat dataframe baru
clean_df = diabetes_df.copy()

# Mengubah nilai 0 pada beberapa fitur menjadi Nan
for col in zero_columns:
    clean_df[col] = diabetes_df[col].apply(lambda x: None if x == 0 else x)

"""**Melakukan proses imputasi dengan teknik regresi**"""

# Membuat objek imputer
imputer = IterativeImputer(estimator=RandomForestRegressor(), random_state=42)
df_imputed = imputer.fit_transform(clean_df)

# Menyimpan hasil imputasi
df_imputed = pd.DataFrame(df_imputed, columns=diabetes_df.columns)

# Menampilkan hasil imputasi
df_imputed

"""**Melihat deskripsi statistik dataset setalah melakukan imputasi nilai 0**"""

# Melihat informasi deskriptif data
df_imputed.describe()

"""**Mendapatkan nilai skew dengan fungsi skew() pada kolom numerik untuk mengetahui distribusi data**"""

# Menyimpan daftar kolom
df_columns = df_imputed.columns

# Melakukan perulangan untuk menghitung nilai skewness tiap kolom
for col in df_columns:
    series = pd.Series(np.array(df_imputed[col]))
    print(f"{col}: {series.skew()}")

"""**Melakukan ploting untuk melihat distribusi data dari kolom numerik apakah right-skewness, normal, atau left-skewness**"""

# Membuat subplot
fig, axes = plt.subplots(3, 3, figsize=(15, 10))

# Melakukan flatten axes array untuk memudahkan iterasi jika diperlukan
axes = axes.flatten()

# Plot setiap kolom
for i, column in enumerate(df_imputed.columns):
    diabetes_df[column].hist(ax=axes[i], bins=15)
    axes[i].set_title(column)
    axes[i].set_xlabel('Value')
    axes[i].set_ylabel('Frequency')

# Menyesuaikan layout agar lebih rapi
plt.tight_layout()
plt.show()

"""**Mengecek tingkat korelasi antar fitur dengan fungsi corr()**"""

# Mengecek korelasi dengan fungsi corr()
df_imputed.corr()

"""**Melakukan ploting korelasi antar fitur dari hasil fungsi corr() dengan heatmap**"""

# Visualisasi korelasi antar variabel numerik
def show_corr_matrix(data):
    plt.figure(figsize=(10, 8))
    corr_matrix = data.corr(numeric_only=True)

    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
    plt.title("Correlation Matrix")
    plt.show()


show_corr_matrix(df_imputed.drop(columns=['Outcome']))

"""**Menyimpan kolom yang memiliki relasi yang cukup tinggi**"""

# Menyimpan nama kolom yang memiliki korelasi yang cukup tinggi ( > 0.5)
high_corr_cols = ['Insulin', 'Glucose', 'BMI', 'SkinThickness', 'Age', 'Pregnancies']

"""**Menghitung jumlah kelas diabates dan non-diabates dan melakukan ploting**"""

# Menggunakan value_counts() untuk menghitung jumlah wanita yang berisiko diabetes dan tidak
df_imputed['Outcome'].value_counts()

plt.figure(figsize=(7, 5))
sns.histplot(x="Outcome", data=df_imputed)

plt.title("Diabetes Outcome", fontsize=20)
plt.tick_params(axis='x', labelsize=15)
plt.show()

"""**Mendapatkan jumlah kelas berdasarkan kategori rentang umur**"""

# Membuat fungsi untuk menentukan kategori berdasarkan rentang umur
def check_age(age):
    if age < 25:
        return "youth"
    elif 25 <= age < 37:
        return "maturity"
    elif 37 <= age < 49:
        return "middle-maturity"
    elif 49 <= age < 61:
        return "full-maturity"
    else:
        return "elderly"


# Membuat DataFrame baru age_df
age_df = df_imputed.copy()

# Mengecek kategori umur berdasarkan rentang umur
age_df['Age'] = age_df['Age'].apply(check_age)

# Menghitung hasil diabetes berdasarkan kategori umur
age_df.groupby(by=['Age', 'Outcome'])['Outcome'].count()

# Mengecek jumlah data berdasarkan kategori umur
age_df['Age'].value_counts()

"""**Melakukan ploting untuk melihat jumlah wanita berdasarkan kategori umur**"""

age_count = age_df['Age'].value_counts().reset_index(name='Count')

plt.figure(figsize=(10, 6))
sns.barplot(
    x='Count',
    y='Age',
    data=age_count,
    errorbar=None,
)

plt.title("Number of people by Age", fontsize=20)
plt.xlabel(None)
plt.ylabel(None)
plt.show()

"""**Melakukan ploting untuk melihat distribusi kelas berdasarkan kategori umur**"""

# Melihat demografi penderita diabetes dan non-diabetes berdasarkan umur
byage_df = age_df.groupby(by=['Age', 'Outcome']).size().reset_index(name='Count')
byage_df['Outcome'] = byage_df['Outcome'].map({0: "Non-Diabetes", 1: "Diabetes"})

plt.figure(figsize=(15, 8))

sns.barplot(
    y="Count",
    x="Age",
    hue='Outcome',
    data=byage_df,
    errorbar=None,
)

plt.tick_params(axis='x', labelsize=15)
plt.xlabel(None)
plt.ylabel(None)
plt.show()

byage_df

"""**Mendapatkan jumlah wanita berdasarkan tingkat tekanan darah**"""

# Membuat fungsi untuk menentukan kategori berdasarkan rentang tekanan darah
def check_blood_pressure(blood_pressure):
    if blood_pressure < 80:
        return "normal"
    elif 80 <= blood_pressure <= 89:
        return "pre-hypertension"
    elif 90 <= blood_pressure <= 99:
        return "stage-1-hypertension"
    else:
        return "stage-2-hypertension"


blood_pressure_df = df_imputed.copy()
blood_pressure_df['BloodPressure'] = blood_pressure_df['BloodPressure'].apply(check_blood_pressure)

blood_pressure_count = blood_pressure_df['BloodPressure'].value_counts()

blood_pressure_count

"""**Melakukan ploting jumlah wanita berdasarkan kondisi  tekanan darah**"""

# Melihat distribusi jumlah wanita berdasarkan tekanan darah
blood_pressure_count = blood_pressure_df['BloodPressure'].value_counts().reset_index(name='Count')

plt.figure(figsize=(10, 6))

sns.barplot(
    y='BloodPressure',
    x='Count',
    data=blood_pressure_count,
    errorbar=None
)

plt.title("Number of People by Blood Pressure", fontsize=12)
plt.xlabel(None)
plt.ylabel(None)
plt.show()

"""**Mendapatkan jumlah kelas berdasarkan kondisi tekanan darah dan melakukan ploting untuk melihat distribusi data**"""

# Menmpilkan hasil diabetes berdasarkan tekanan darah
blood_pressure_df.groupby(by=['BloodPressure', 'Outcome'])['Outcome'].count()

# Melihat distribusi penderita diabetes dan non-diabates berdasarkan tekanan darah
bybloodpressure_df = blood_pressure_df.groupby(by=['BloodPressure', 'Outcome']).size().reset_index(name='Count')
bybloodpressure_df['Outcome'] = bybloodpressure_df['Outcome'].map({0: 'Non-Diabetes', 1: 'Diabetes'})

plt.figure(figsize=(15, 8))

sns.barplot(
    y='Count',
    x='BloodPressure',
    hue='Outcome',
    data=bybloodpressure_df,
    errorbar=None
)

plt.title("Number of Class by Blood Pressure", fontsize=20)
plt.tick_params(axis='x', labelsize=15)
plt.show()

"""**Mendapatkan jumlah wanita berdasarkan  BMI**"""

# Membuat fungsi untuk menentukan kategori berdasarkan BMI
def check_bmi(bmi):
    if bmi < 18.5:
        return "underweight"
    elif 18.5 <= bmi <= 24.9:
        return "normal"
    elif 25 <= bmi <= 29.9:
        return "overweight"
    else:
        return "obese"


bmi_df = df_imputed.copy()
bmi_df['BMI'] = bmi_df["BMI"].apply(check_bmi)

bmi_df["BMI"].value_counts()

"""**Melakukan ploting untuk melihat distribusi jumlah wanita berdasarkan BMI**"""

bmi_count = bmi_df['BMI'].value_counts().reset_index(name='Count')

plt.figure(figsize=(10, 6))

sns.barplot(
    y='BMI',
    x='Count',
    data=bmi_count,
    errorbar=None,
)

plt.title("Number of people by BMI", fontsize=20)
plt.xlabel(None)
plt.ylabel(None)
plt.show()

"""**Mendapatkan jumlah kelas berdasarkan BMI dan melakukan ploting untuk melihat distribusi data**"""

# Menampilkan hasil diabetes berdasarkan BMI
bmi_df.groupby(by=['BMI', 'Outcome'])['Outcome'].count()

# Melihat demografi penderita diabetes dan non-diabetes berdasarkan BMI
bybmi_df = bmi_df.groupby(by=['BMI', 'Outcome']).size().reset_index(name='Count')
bybmi_df['Outcome'] = bmi_df['Outcome'].map({0: "Non-Diabetes", 1: "Diabetes"})

plt.figure(figsize=(15, 8))

sns.barplot(
    y='Count',
    x='BMI',
    hue='Outcome',
    data=bybmi_df,
    errorbar=None
)

plt.tick_params(axis='x', labelsize=15)
plt.show()

"""**Melihat proporsi kelas diabates dan non-diabates menggunakan pie chart**"""

# Menghitung jumlah data berdasarkan hasil diabetes (0 dan 1)
outcome_count = df_imputed['Outcome'].value_counts().tolist()

plt.pie(
    x=outcome_count,
    labels=('Non-Diabetes', 'Diabetes'),
    autopct='%1.1f%%',
    explode=(0.05, 0)
)

plt.show()

"""**Mengecek outlier pada fitur numerik**"""

# Melihat distribusi pada data kuantitatif
df_columns = df_imputed.drop(columns=['Outcome']).columns

fig, axes = plt.subplots(3, 3, figsize=(15, 10))

axes = axes.flatten()

for i, column in enumerate(df_columns):
    sns.boxplot(x=df_imputed[column], ax=axes[i])

# Menghapus subplot yang tidak terpakai jika ada
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""## **Data Preparation**

### **Standardization of Features**

**Melakukan scaling fitur menggunakan MinMaxScaler() untuk mengubah skala menjadi rentang 0 - 1**
"""

# Standarisasi fitur numerik
scaler = MinMaxScaler()

# Memilih fitur numerik
std_numeric = df_imputed.drop(columns=['Outcome']).columns

# Membuat dataframe baru
diabetes_std_df = df_imputed.copy()

# Melakukan standarisasi
diabetes_std_df[std_numeric] = scaler.fit_transform(df_imputed[std_numeric])

diabetes_std_df

"""### **Features Selection**

**Melakukan proses seleksi fitur menggunakan metode embedded**
"""

# Memisahkan data mejadi fitur dan label
X = diabetes_std_df.drop(columns=['Outcome'])
y = diabetes_std_df['Outcome']

# Embedded Methods
# menggunakan Random Forest untuk mendapatkan fitur penting
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X, y)

# Mendapatkan fitur penting
importance = rf_model.feature_importances_
indices = np.argsort(importance)[::-1]

# Meenentukan ambang batas untuk fitur penting
threshold = 0.05
important_features_indices = [i for i in range(len(importance)) if importance[i] >= threshold]

# Menampilkan fitur penting beserta nilainya
print("Fitur yang dipilih dengan Embedded Methods (di atas ambang batas > 0.05):\n")
for i in important_features_indices:
    # Jika X asli berbentuk DataFrame, maka kita ambil nama kolom
    print(f"{X.columns[i]}: {importance[i]}")

# Mendapatkan nama kolom penting berdasarkan importace
important_features = X.columns[important_features_indices]

# Memindahkan fitur penting ke variabel baru
X_important = X[important_features]

# X_important sekarang berisi hanya fitur penting
print("\nDimensi data pelatihan dengan fitur penting:", X_important.shape)

"""### **SMOTE Oversampling**

**Mengatasi kelas minoritas dengan melakukan Oversampling dengan metode SMOTE**
"""

# Mengecek distribusi kelas target
Counter(diabetes_std_df['Outcome'].map({0: "Non-Diabetes", 1: "Diabetes"}))

# Inisialisasi SMOTE
smote = SMOTE(random_state=42)

# Melakukan oversampling pada dataset
X_resampled, y_resampled = smote.fit_resample(X_important, y)

# Menampilkan distribusi kelas setelah SMOTE
print("Distribusi kelas setelah SMOTE:", Counter(y_resampled.map({0: "Non-Diabetes", 1: "Diabetes"})))

# Mengubah hasil menjadi DataFrame untuk analisis lebih lanjut
X_resampled = pd.DataFrame(X_resampled)
y_resampled = pd.Series(y_resampled, name='Target')

"""### **Dimension Reduction**

**Melakukan reduksi dimensi pada kolom yang memiliki korelasi yang cukup tinggi**
"""

# Inisialisasi PCA
pca = PCA(n_components=0.9, random_state=42)

# Melakukan PCA untuk kolom yang memiliki korelasi cukup tinggi
X_pca = pca.fit_transform(X_resampled[high_corr_cols])
pca.explained_variance_.round(3)

# Membuat dataframe baru untuk menyimpan hasil reduksi
df_pca = pd.DataFrame(data=X_pca, columns=['pca_1', 'pca_2', 'pca_3', 'pca_4'])

X_final = pd.concat([
    X_resampled.drop(columns=high_corr_cols),
    df_pca
], axis=1)

X_final.head(5)

"""### **Spliting Data Training and Testing**

**Membagi dataset menjadi dua bagian yaitu data latih dan data uji dengan perbandingan 80:20**
"""

X_train, X_test, y_train, y_test = train_test_split(X_final, y_resampled, test_size=0.2, random_state=42)

"""## **Building Model**

**Membangun model prediksi diabetes dengan tiga algoritma yaitu Random Forest, K-Nearest-Neighbors dan Logistic Regression**
"""

# Pelatihan model
random_forest = RandomForestClassifier(random_state=42).fit(X_train, y_train)
knn = KNeighborsClassifier().fit(X_train, y_train)
lr = LogisticRegression(random_state=42).fit(X_train, y_train)

print("Training model selesai")

"""## **Evaluation Model**

**Melakukan evaluasi model dengan confusion matrix dan melihat performa model berdasarkan metrik akurasi, precision, recall dan f1-score**
"""

# Fungsi untuk mengevaluasi dan mengembalikan hasil sebagai kamus
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)

    evaluate_results = {
        'Confusion Matrix': cm,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1 Score': f1_score(y_test, y_pred)
    }

    return evaluate_results


# Mengevaluasi setiap model dan mengumpulkan hasilnya
results = {
    'Random Forest': evaluate_model(random_forest, X_test, y_test),
    'KNN': evaluate_model(knn, X_test, y_test),
    'LR': evaluate_model(lr, X_test, y_test)
}


def print_evaluate_model(result_list):
    # Memuat dataframe untuk meringkas hasil
    summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])

    # Mengisi dataframe dengan hasil
    rows = []
    for model_name, metrics in result_list.items():
        rows.append({
            'Model': model_name,
            'Accuracy': metrics['Accuracy'],
            'Precision': metrics['Precision'],
            'Recall': metrics['Recall'],
            'F1 Score': metrics['F1 Score']
        })

    # Mengkonversi daftar kamus menjadi dataframe
    summary_df = pd.DataFrame(rows)

    # Menampilkan dataframe
    print(summary_df)


print_evaluate_model(results)

"""**Membuat fungsi untuk melakukan ploting confusion matrix**"""

# Membuat fungsi untuk melakukan ploting hasil evaluasi confusion matrix
def plot_confusion_matrix(cm):
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()

"""**Menampilkan confusion matrix pada model Random Forest sebelum dilakukan hyperparameter tuning**"""

# Plot hasil model Random Forest
plot_confusion_matrix(results['Random Forest']['Confusion Matrix'])

"""**Menampilkan confusion matrix pada model K-Nearest-Neighbors sebelum dilakukan hyperparameter tuning**"""

# Plot hasil model Ada Boost
plot_confusion_matrix(results['KNN']['Confusion Matrix'])

"""**Menampilkan confusion matrix pada model Logistic Regression sebelum dilakukan hyperparameter tuning**"""

plot_confusion_matrix(results['LR']['Confusion Matrix'])

"""## **Tuning Model**

**Melakukan hyperparameter tuning menggunakan GridSearchCV pada model Random Forest**
"""

# Definisikan parameter grid untuk Grid Search (Random Forest)
param_grid_rf = {
    'n_estimators': [10, 50, 100, 300],
    'max_depth': np.arange(1, 10, 1),
    'min_samples_split': np.arange(2, 10, 1)
}

# Inisialisasi GridSearchCV
grid_search_rf = GridSearchCV(random_forest, param_grid_rf, cv=5, n_jobs=1, verbose=2)
grid_search_rf.fit(X_train, y_train)

# Output hasil terbaik
print(f"Best parameters for Random Forest: {grid_search_rf.best_params_}")
best_rf_grid = grid_search_rf.best_estimator_

# Evaluasi performa model pada test set
grid_search_rf_score = best_rf_grid.score(X_test, y_test)
print((f"Accuracy RF after Grid Search: {grid_search_rf_score}"))

# Menyimpan hasil tuning
n_estimators = grid_search_rf.best_params_['n_estimators']
max_depth = grid_search_rf.best_params_['max_depth']
min_samples_split = grid_search_rf.best_params_['min_samples_split']

"""**Melakukan hyperparameter tuning menggunakan GridSearchCV pada model K-Nearest-Neighbors**"""

# Definisikan parameter grid untuk Grid Search
param_grid_knn = {
    'n_neighbors': np.arange(5, 20, 1),
    'metric': ['minkowski', 'manhattan', 'euclidean']
}

# Inisialisasi GridSearchCV
grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5, n_jobs=1, verbose=2)
grid_search_knn.fit(X_train, y_train)

# Output hasil terbaik
print(f"Best parameters for KNN: {grid_search_knn.best_params_}")
best_knn_grid = grid_search_knn.best_estimator_

# Evaluasi performa model pada test set
grid_search_knn_score = best_knn_grid.score(X_test, y_test)
print((f"Accuracy KNN after Grid Search: {grid_search_knn_score}"))

# Menyimpan hasil tuning
n_neighbors = grid_search_knn.best_params_['n_neighbors']
metric = grid_search_knn.best_params_['metric']

"""**Melakukan hyperparameter tuning menggunakan GridSearchCV pada model Logistic Regression**"""

# Definisikan parameter grid untuk Grid Search
param_grid_lr = {
    'C': [0.1, 1, 10],
    'penalty': ['l2', 'l1', 'elasticnet'],
    'solver': ['lbfgs', 'liblinear', 'saga']
}

# Inisialisasi GridSearchCV
grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=5, n_jobs=1, verbose=2)
grid_search_lr.fit(X_train, y_train)

# Output hasil terbaik
print(f"Best parameters (Grid Search): {grid_search_lr.best_params_}")
best_lr_grid = grid_search_lr.best_estimator_

# Evaluasi performa model pada test set
grid_search_score_lr = best_lr_grid.score(X_test, y_test)
print(f"Accuracy LR after Grid Search: {grid_search_score_lr:.2f}")

# Menyimpan hyperparameter terbaik di vairabel
best_c_lr = grid_search_lr.best_params_['C']
best_penalty = grid_search_lr.best_params_['penalty']
best_solver = grid_search_lr.best_params_['solver']

"""## **Evaluasi Model Klasifikasi setelah Tuning**

**Setelah melakukan hyperparameter tuning, nilai dari best parameter diujikan ke pada ketiga model untuk melihat bagaimana performanya**
"""

# Inisialisasi model klasifikasi setelah dilakukan tuning
rf_tuning = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=42).fit(X_train, y_train)
knn_tuning = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric).fit(X_train, y_train)
lr_tuning = LogisticRegression(C=best_c_lr, penalty=best_penalty, solver=best_solver, random_state=42).fit(X_train, y_train)

# Evaluasi ulang model
results_after_tuning = {
    'Random Forest': evaluate_model(rf_tuning, X_test, y_test),
    'KNN': evaluate_model(knn_tuning, X_test, y_test),
    'LR': evaluate_model(lr_tuning, X_test, y_test)
}

# Menampilkan hasil evaluasi setelah tuning
print_evaluate_model(results_after_tuning)

"""**Menampilkan confusion matrix pada model Random Forest setelah dilakukan hyperparameter tuning**"""

plot_confusion_matrix(results_after_tuning['Random Forest']['Confusion Matrix'])

"""**Menampilkan confusion matrix pada model K-Nearest-Neighbors setelah dilakukan hyperparameter tuning**"""

plot_confusion_matrix(results_after_tuning['KNN']['Confusion Matrix'])

"""**Menampilkan confusion matrix pada model Logistic Regression setelah dilakukan hyperparameter tuning**"""

plot_confusion_matrix(results_after_tuning['LR']['Confusion Matrix'])